{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:\\\\Users\\\\HP\\\\Desktop\\\\terry dtops data\\\\Terry_Stops_20240301.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i'm Summarizing numerical columns and round to 3 decimal places\n",
    "numerical_summary = df.describe().round(3)\n",
    "\n",
    "print(numerical_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over columns to identify categorical variables\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        unique_values = df[column].unique()\n",
    "        print(f\"Unique values for {column}: {unique_values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting the relevant data for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "relevant_columns = ['Officer Race', 'Subject Perceived Race', 'Stop Resolution', 'Frisk Flag', 'Arrest Flag','Precinct', 'Beat', 'Initial Call Type', 'Final Call Type']\n",
    "\n",
    "# storing them into a new dataset\n",
    "data2 = df[relevant_columns]\n",
    "\n",
    "print(data2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "race composition grapgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_counts = data2['Officer Race'].value_counts()\n",
    "\n",
    "# Plotting the race composition\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=race_counts.index, y=race_counts.values, palette='viridis')\n",
    "plt.title('Race Composition of Officers')\n",
    "plt.xlabel('Officer Race')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')  \n",
    "plt.tight_layout()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of subject perceived race with rotated labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Subject Perceived Race', data=data2, palette='viridis')\n",
    "plt.title('Distribution of Subject Perceived Race')\n",
    "plt.xlabel('Subject Perceived Race')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)  \n",
    "plt.tight_layout()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relation ship between officer and subject race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# i'm Creating a pivot table to count occurrences of each combination of races\n",
    "pivot_table = data2.pivot_table(index='Officer Race', columns='Subject Perceived Race', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_table, annot=True, fmt='d', cmap='viridis')\n",
    "plt.title('Relationship between Officer Race and Subject Perceived Race')\n",
    "plt.xlabel('Subject Perceived Race')\n",
    "plt.ylabel('Officer Race')\n",
    "plt.xticks(rotation=45, ha='right')  \n",
    "plt.yticks(rotation=0, va='center')  \n",
    "plt.tight_layout()  \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data2.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing: Relationship Between Officer's Race and Stop Resolution\n",
    "\n",
    "### Hypotheses:\n",
    "- **Null Hypothesis (H0):** There is no association between the officer's race and the stop resolution.\n",
    "- **Alternative Hypothesis (H1):** There is an association between the officer's race and the stop resolution.\n",
    "\n",
    "### Finding:\n",
    "Based on the small p-value obtained from the chi-square test (much smaller than the significance level of 0.05), we reject the null hypothesis in favor of the alternative hypothesis, indicating that there is indeed a significant association between the officer's race and the stop resolution.\n",
    "This analysis suggests that the type of stop resolution is not independent of the officer's race, indicating potential biases or underlying factors influencing the stop resolution based on the officer's race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Assuming data2 is properly defined DataFrame\n",
    "\n",
    "# Creating a contingency table\n",
    "contingency_table = pd.crosstab(data2['Officer Race'], data2['Stop Resolution'])\n",
    "\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "# Calculating chi-square statistic and p-value\n",
    "chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "print(\"\\nChi-square Statistic:\", chi2)\n",
    "print(\"P-value:\", p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the relationship between the officer's race and stop resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the stacked bar plot\n",
    "contingency_table.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "plt.title('Stop Resolution by Officer Race')\n",
    "plt.xlabel('Officer Race')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title='Stop Resolution')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arrest rates by race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=data2, x='Officer Race', hue='Arrest Flag')\n",
    "\n",
    "\n",
    "plt.title('Arrest Rates by Officer Race')\n",
    "plt.xlabel('Officer Race')\n",
    "plt.ylabel('Arrest Rate')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the proportions or percentages to compare the likelihood of frisks or arrests across different racial groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'Frisk Flag' and 'Arrest Flag' columns to numeric (0 for 'N', 1 for 'Y')\n",
    "data2['Frisk Flag'] = data2['Frisk Flag'].map({'Y': 1, 'N': 0})\n",
    "data2['Arrest Flag'] = data2['Arrest Flag'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# Computing total frisks and arrests for each racial group of officers and subjects\n",
    "total_frisks = data2['Frisk Flag'].sum()\n",
    "total_arrests = data2['Arrest Flag'].sum()\n",
    "\n",
    "# Computing frisk and arrest counts for each racial group of officers and subjects\n",
    "frisk_counts = data2.groupby(['Officer Race', 'Subject Perceived Race'])['Frisk Flag'].sum()\n",
    "arrest_counts = data2.groupby(['Officer Race', 'Subject Perceived Race'])['Arrest Flag'].sum()\n",
    "\n",
    "# Computing proportions or percentages\n",
    "frisk_proportions = frisk_counts / total_frisks\n",
    "arrest_proportions = arrest_counts / total_arrests\n",
    "\n",
    "print(\"Frisk Proportions:\")\n",
    "print(frisk_proportions)\n",
    "print(\"\\nArrest Proportions:\")\n",
    "print(arrest_proportions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frisk and arrest visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting frisk proportions\n",
    "plt.figure(figsize=(14, 8))  # Enlarge the figure size\n",
    "frisk_proportions.unstack().plot(kind='bar', stacked=True)\n",
    "plt.title('Proportions of Frisks by Officer Race and Subject Perceived Race')\n",
    "plt.xlabel('Officer Race')\n",
    "plt.ylabel('Proportion of Frisks')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Subject Perceived Race')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting arrest proportions\n",
    "plt.figure(figsize=(14, 8))  # Enlarge the figure size\n",
    "arrest_proportions.unstack().plot(kind='bar', stacked=True)\n",
    "plt.title('Proportions of Arrests by Officer Race and Subject Perceived Race')\n",
    "plt.xlabel('Officer Race')\n",
    "plt.ylabel('Proportion of Arrests')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Subject Perceived Race')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Encoding categorical variables\n",
    "data2_encoded = pd.get_dummies(data2, drop_first=True) \n",
    "\n",
    "# Performing feature scaling or normalization\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data2_encoded)\n",
    "\n",
    "# training and testing sets splits\n",
    "X = pd.DataFrame(scaled_features, columns=data2_encoded.columns)  \n",
    "X.drop(columns=['Arrest Flag'], inplace=True) \n",
    "y = data2['Arrest Flag'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My test splits with random state 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Modeling\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
